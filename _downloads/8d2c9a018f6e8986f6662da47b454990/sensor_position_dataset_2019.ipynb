{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SensorPositionDataset2019 - Full mocap reference data set with 6 sensors per foot\n\nWe provide 2 versions of the dataset:\n\nSensorPositionDatasetSegmentation: In this dataset no Mocap ground truth is provided and the IMU data is not cut to\n    the individual gait test, but just a single recording for all participants exists with all tests (including\n    failed ones) and movement between the tests.\n    This can be used for stride segmentation tasks, as we hand-labeled all stride-start-end events in these recordings\nSensorPositionDatasetMocap: In this dataset the data is cut into the individual tests.\n    This means 7 data segments exist per participants.\n    For each of these segments full synchronised motion capture reference is provided.\n\nFor more information about the dataset, see the dataset [documentation](https://zenodo.org/record/5747173)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>For this example to work, you need to modify the dataset path in the following line to point to the\n             location of the data on your machine.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\ndataset_path = Path(\n    \"/home/arne/Documents/repos/work/projects/sensor_position_comparison\" \"/sensor_position_main_analysis/data/raw\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SensorPositionComparison2019Segmentation\nThis version of the dataset contains one recording per participant with all tests and movement between the tests.\nNo Mocap reference is provided, but just the IMU data and the stride borders based on the IMU data.\n\nBy default, the data of all sensors is provided and the data for each sensor is aligned based on the roughly known\norientation of the sensor, so that the coordinate system of the insole sensor (see dataset documentation) can be\nused for all sensors.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from joblib import Memory\n\nfrom mad_datasets.sensor_position_comparison_2019 import SensorPositionComparison2019Segmentation\n\ndataset = SensorPositionComparison2019Segmentation(\n    data_folder=dataset_path,\n    memory=Memory(\"../.cache\"),\n)\ndataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that we have 14 participants.\nUsing the dataset class, we can select any subset of participants.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subset = dataset.get_subset(participant=[\"4d91\", \"5047\"])\nsubset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have the selection of data we want to work with, we can iterate the dataset object to access the data of\nindividual datapoints or just index it as below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datapoint = subset[0]\ndatapoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On this datapoint, we can now access the data.\nWe will start with the metadata.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datapoint.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we can access the synchronised data of the individual sensors.\nThe data is stored as a multi-column pandas DataFrame with the time as index.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data = datapoint.data\nimu_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we provide hand-labeled stride borders for the IMU data.\nAll strides are labeled based on the minima in the gyr_ml signal (see dataset documentation for more details).\n\nNote that we use a trailing `_` to indicate that this is data calculated based on the ground truth/manual labels and\nnot just the IMU data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "segmented_stride_labels = datapoint.segmented_stride_list_[\"left\"]\nsegmented_stride_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively to the `segmented_stride_list_` we also provide the `segmented_stride_list_per_sensor_` makes it\neasier to directly access the stride borders for a specific sensor (note they are still the same, as before,\nas only one stridelist per foot exists).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "segmented_stride_labels = datapoint.segmented_stride_list_per_sensor_[\"l_insole\"]\nsegmented_stride_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we plot the IMU data (acc on top, gyro on bottom) and the stride borders for a small part of the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nsensor = \"l_insole\"\nfig, axes = plt.subplots(2, 1, sharex=True, figsize=(10, 5))\nimu_data[sensor].filter(like=\"gyr\").plot(ax=axes[0])\nimu_data[sensor].filter(like=\"acc\").plot(ax=axes[1])\nfor (i, s) in datapoint.segmented_stride_list_[\"left\"].iterrows():\n    s /= datapoint.sampling_rate_hz\n    axes[0].axvspan(s[\"start\"], s[\"end\"], alpha=0.2, color=\"C1\")\n    axes[1].axvspan(s[\"start\"], s[\"end\"], alpha=0.2, color=\"C1\")\n\naxes[0].set_xlim(300, 350)\nfig.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SensorPositionComparison2019Mocap\nFor this version of the dataset, the data is split into the individual tests.\nThis means 7 data segments exist per participants.\nFor details about the respective tests, see the dataset documentation.\n\nFor each of these segments full synchronised motion capture trajectory of all markers is provided.\nFurther, we provide labels for IC and TC derived from the motion capture data for each of the hand labeled strides\nwithin the segments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from mad_datasets.sensor_position_comparison_2019 import SensorPositionComparison2019Mocap\n\ndataset = SensorPositionComparison2019Mocap(\n    data_folder=dataset_path,\n    memory=Memory(\"../.cache\"),\n)\ndataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that one individual data point for this dataset is only one of the gaittests.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datapoint = dataset[0]\ndatapoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access the entire trajectory of the motion capture markers for this segment.\nNote, that we don't provide any mocap-derived ground truth for any spatial parameters, but assume that they will be\ncalculated from the trajectory depending on the task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data = datapoint.data\nmocap_traj = datapoint.marker_position_\nmocap_traj.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the data of the heel marker (fcc) and the imu data of the insole sensor together to show that they are\nsynchronised.\nBoth data streams have the correct time axis, even though they are sampled at different rates (mocap is sampled\nwith 100 hz, and IMU with 204.8).\nKeep that in mind, when working with the data without an index (e.g. after converting to numpy arrays).\n\nTo better visualize the data we \"normalize\" the mocap data by subtracting the first position.\nThis way we can clearly see the individual strides.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(10, 5))\nimu_data[\"l_insole\"].filter(like=\"gyr\").plot(ax=axes[0])\nmocap_traj[\"l_fcc\"].sub(mocap_traj[\"l_fcc\"].iloc[0]).plot(ax=axes[1])\naxes[0].set_xlim(0, 7.5)\naxes[0].set_ylabel(\"IMU gyr [rad/s]\")\naxes[1].set_ylabel(\"Marker Trajectory [mm]\")\nfig.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Like before we have access to the segmented strides (however, only cut for the respective region).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "segmented_stride_labels = datapoint.segmented_stride_list_[\"left\"]\nsegmented_stride_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access the labels for IC and TC.\nEven though we used the hand labeled strides as regions of interest for segmentation, we can see that the start and\nend labels of the mocap event strides and the hand labeled strides are not identical.\nThis is because the event list is provided in the samples of the motion capture data, while the hand labeled strides\nare provided in the samples of the IMU data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "event_labels = datapoint.mocap_events_[\"left\"]\nevent_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To avoid errors in potential conversions between the two domains (mocap/IMU), we provide the\n`convert_with_padding` methods to convert the event list.\n(To understand why the method is called `..._with_padding`, see the section below).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "event_labels_in_imu = datapoint.convert_with_padding(event_labels, from_time_axis=\"mocap\", to_time_axis=\"imu\")\nevent_labels_in_imu.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you can see, that the start and end labels are (almost) identical.\nRemaining differences are due to rounding errors.\nThis is not ideal, but should not affect typical analysis.\n\nBelow we plotted the segmented strides and the IC and TC labels onto the gyr-y axis and the mocap z-axis (foot lift).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(10, 5))\ngyr_y = imu_data[\"l_insole\"][\"gyr_y\"]\nnorm_mocap_z = mocap_traj[\"l_fcc\"].sub(mocap_traj[\"l_fcc\"].iloc[0])[\"z\"]\ngyr_y.plot(ax=axes[0])\nnorm_mocap_z.plot(ax=axes[1])\nevent_labels_in_mocap = event_labels\nevent_labels_times = datapoint.convert_with_padding(event_labels, from_time_axis=\"mocap\", to_time_axis=\"time\")\nevent_labels_in_imu = datapoint.convert_with_padding(event_labels, from_time_axis=\"mocap\", to_time_axis=\"imu\")\nfor (i, s) in event_labels_times.iterrows():\n    axes[0].axvspan(s[\"start\"], s[\"end\"], alpha=0.2, color=\"C1\")\n    axes[1].axvspan(s[\"start\"], s[\"end\"], alpha=0.2, color=\"C1\")\naxes[0].scatter(\n    event_labels_times[\"ic\"],\n    gyr_y.iloc[event_labels_in_imu[\"ic\"]],\n    marker=\"s\",\n    color=\"k\",\n    zorder=10,\n    label=\"IC\",\n)\naxes[0].scatter(\n    event_labels_times[\"tc\"],\n    gyr_y.iloc[event_labels_in_imu[\"tc\"]],\n    marker=\"o\",\n    color=\"C3\",\n    zorder=10,\n    label=\"TC\",\n)\naxes[1].scatter(\n    event_labels_times[\"ic\"],\n    norm_mocap_z.iloc[event_labels_in_mocap[\"ic\"]],\n    marker=\"s\",\n    color=\"k\",\n    zorder=10,\n    label=\"IC\",\n)\naxes[1].scatter(\n    event_labels_times[\"tc\"],\n    norm_mocap_z.iloc[event_labels_in_mocap[\"tc\"]],\n    marker=\"o\",\n    color=\"C3\",\n    zorder=10,\n    label=\"TC\",\n)\n\naxes[0].legend()\naxes[0].set_xlim(0, 7.5)\naxes[0].set_ylabel(\"IMU gyr [rad/s]\")\naxes[1].set_ylabel(\"Marker Trajectory [mm]\")\nfig.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data padding\nOne issue that you might run into when working with the mocap version of the dataset is that the start of the test\n(which is used to cut the signal) is right  at the beginning of the movement.\nThis means for algorithms that require a certain resting period (e.g. to do a gravity alignment) might not work well.\nTherefore, we provide a `data_padding_s` parameter that will load that amount of seconds before and after the\nactual test.\n\nOn the time axis, we assign negative time stamps to all the padded values that are before the actual test start.\nThis ensures that the time axis of the IMU data and the mocap data are still aligned, even tough no mocap data\nexists in the padded region.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = SensorPositionComparison2019Mocap(\n    data_folder=dataset_path,\n    memory=Memory(\"../.cache\"),\n    data_padding_s=3,\n)\ndatapoint = dataset[0]\nimu_data = datapoint.data\nmocap_traj = datapoint.marker_position_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the data is now padded with 3 seconds before and after the test, however no mocap samples exist in\nthese regions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(10, 5))\nimu_data[\"l_insole\"].filter(like=\"gyr\").plot(ax=axes[0])\nmocap_traj[\"l_fcc\"].sub(mocap_traj[\"l_fcc\"].iloc[0]).plot(ax=axes[1])\naxes[0].set_ylabel(\"IMU gyr [rad/s]\")\naxes[1].set_ylabel(\"Marker Trajectory [mm]\")\nfig.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While the time axis of the IMU data is still aligned with the mocap data, care needs to be taken when it comes to\nthe event data.\nOnly events/labels provided with IMU samples (or with a time axis) respect the padding correctly.\nFor example, the `segmented_stride_list` is provided with in IMU samples, so it is padded correctly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "segmented_stride_labels = datapoint.segmented_stride_list_[\"left\"]\nsegmented_stride_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, to correctly transform it to the time domain, you need to manually add the padding time.\nTo avoid erros, we provide the `convert_with_padding` method that does this for you.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "segmented_stride_labels_time = datapoint.convert_with_padding(\n    segmented_stride_labels, from_time_axis=\"imu\", to_time_axis=\"time\"\n)\nsegmented_stride_labels_time.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Values provided in mocap samples, don't have any padding applied.\nHowever, for the like with the segmented_stride_list, you can use `convert_with_padding` to transform them to IMU\nsamples with correct padding.\n\nFirst no padding, mocap samples\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "event_labels_in_mocap = datapoint.mocap_events_[\"left\"]\nevent_labels_in_mocap.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In IMU samples with padding:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "event_labels_in_imu = datapoint.convert_with_padding(event_labels_in_mocap, from_time_axis=\"mocap\", to_time_axis=\"imu\")\nevent_labels_in_imu.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And in time (seconds) with padding:\nBelow you can see that the first event is now after 4 seconds, indicating that the signal is correctly padded.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "event_labels_times = datapoint.convert_with_padding(event_labels_in_mocap, from_time_axis=\"mocap\", to_time_axis=\"time\")\nevent_labels_times.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}