{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# PyShoe2019 - Indoor Navigation with foot-mounted inertial sensors\n\nThe PyShoe dataset [1]_ contains multiple trials with spatial reference for longer trials.\nThis makes it perfect to benchmark trajectory reconstruction algorithms.\nHowever, it does not contain any temporal marker or stride reference.\n\n## General information\nThe dataset was recorded with a LORD MicroStrain 3DM-GX5-25 IMU sensor.\nA single IMU node was attached on the top of the right shoe.\n\nOn loading, we transform the data to the coordinate system of the gaitmap coordinate system as shown below\n\n.. figure:: /images/coordinate_systems/coordinate_transform_microstrain_instep_pyshoe.svg\n    :alt: coordinate system definition\n    :figclass: align-center\n\nThe data is split into three parts:\n\n- Vicon: Individual trials recorded with a Vicon motion capture system as reference\n- Hallway: Multiple longer walking/running trials recorded with specific landmarks as positional reference along the\n  trial\n- Stairs: Multiple trials from a single participant recorded with a stair climbing task\n\nFor each part of the data we provide a separate dataset class.\n\n.. [1] Wagstaff, Brandon, Valentin Peretroukhin, and Jonathan Kelly.\n       \u201cRobust Data-Driven Zero-Velocity Detection for Foot-Mounted Inertial Navigation.\u201d IEEE Sensors Journal 20,\n       no. 2 (January 15, 2020): 957\u201367. https://doi.org/10.1109/JSEN.2019.2944412.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>For this example to work, you need to have a global config set containing the path to the dataset.\n             Check the `README.md` for more information.</p></div>\n\n## Vicon Dataset\nFirst we will create a simple instance of the dataset class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap_datasets.pyshoe_2019 import PyShoe2019Vicon\n\ndataset = PyShoe2019Vicon()\ndataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the index you can select individual trials.\nNote, that some of the trials contain running/shuffling or backward walking.\nHowever, the dataset authors do not provide a label for that (https://github.com/utiasSTARS/pyshoe/issues/11).\nIf it is important to you to only consider trials containing movements of a specific type, you need to manually\ncheck the raw data and guess based on that.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trial = dataset.get_subset(trial=\"2017-11-22-11-22-03\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we have selected a single trial, we can access the data.\nThe data is stored in a pandas DataFrame, where each row corresponds to a single time step.\nNote, that the dataset only contains data from a single IMU attached to the right shoe.\nWe still provide the data as a \"nested\" dataframe, where the outermost level corresponds to the foot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data = trial.data\nimu_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mocap marker data is also stored in a pandas DataFrame and the marker is placed directly on the sensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mocap_data = trial.marker_position_\nmocap_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both data types are recorded at 200 Hz and are synchronized.\nThis means we can plot them in an aligned way without any modifications.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(3, 1, sharex=True)\nimu_data[\"right_sensor\"].filter(like=\"acc\").plot(ax=axs[0])\nimu_data[\"right_sensor\"].filter(like=\"gyr\").plot(ax=axs[1])\nmocap_data[\"right_sensor\"].plot(ax=axs[2])\naxs[2].set_xlabel(\"Time [s]\")\naxs[2].set_ylabel(\"Position [m]\")\naxs[1].set_ylabel(\"Gyro [deg/s]\")\naxs[0].set_ylabel(\"Acc [m/s^2]\")\n\nfig.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hallway Dataset\nFirst we will create a simple instance of the dataset class.\nWe can see that the dataset contains trials from multiple participants with the three trial types (walking, running,\ncombined).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap_datasets.pyshoe_2019 import PyShoe2019Hallway\n\ndataset = PyShoe2019Hallway()\ndataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can select arbitrary subsets of the data.\nFor example, we can select all combined (running+walking) trials of a specific participant.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subset = dataset.get_subset(participant=\"p1\", type=\"comb\")\nsubset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we have selected a single trial, we can access the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trial = subset[0]\ntrial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access the IMU data as before.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data = trial.data\nimu_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reference position is only provided for individual points along the trial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reference = trial.position_reference_\nreference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The index of the reference corresponds to timestamps in the IMU data.\nHence, we can easily get the IMU data for the time points of the reference (or the position, once we have calculated\nit based on the IMU data).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data.loc[reference.index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we plot all the data together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(3, 1, sharex=True)\nimu_data[\"right_sensor\"].filter(like=\"acc\").plot(ax=axs[0])\nimu_data[\"right_sensor\"].filter(like=\"gyr\").plot(ax=axs[1])\nreference[\"right_sensor\"].plot(ax=axs[2], style=\"o\")\naxs[2].set_ylabel(\"Position [m]\")\naxs[1].set_ylabel(\"Gyro [deg/s]\")\naxs[0].set_ylabel(\"Acc [m/s^2]\")\n\nfig.tight_layout()\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stairs Dataset\nThe dataset contains trails of a participant walking different number of levels of stairs in starcase.\nFor each number of stairs one trail exists that starts with the participant walking down and then back up (\n`first_direction=\"down\"`) and one trial that starts with the participant walking up and then back down (\n`first_direction=\"up\"`).\n\nFirst we will create a simple instance of the dataset class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap_datasets.pyshoe_2019 import PyShoe2019Stairs\n\ndataset = PyShoe2019Stairs()\ndataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can simply select either the trials starting with going down the up or down trials.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subset = dataset.get_subset(first_direction=\"down\")\nsubset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we have selected a single trial, we can access the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trial = subset.get_subset(n_levels=\"6\")\ntrial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access the IMU data as before.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data = trial.data\nimu_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As with the hallway dataset the reference position is only provided for individual points along the trial.\nFurther, as the reference is derived from the stair geometry, reference only exist for the z-axis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reference = trial.position_reference_\nreference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we plot all the data together.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(3, 1, sharex=True)\nimu_data[\"right_sensor\"].filter(like=\"acc\").plot(ax=axs[0])\nimu_data[\"right_sensor\"].filter(like=\"gyr\").plot(ax=axs[1])\nreference[\"right_sensor\"].plot(ax=axs[2], style=\"o\")\naxs[2].set_ylabel(\"Position [m]\")\naxs[1].set_ylabel(\"Gyro [deg/s]\")\naxs[0].set_ylabel(\"Acc [m/s^2]\")\n\nfig.tight_layout()\nfig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}