{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# StairAmbulationHealthy2021 - A Stride Segmentation and Event Detection dataset with focus on stairs\n\nThe dataset can be downloaded from here:\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The dataset only contains the healthy participants of the full dataset presented in the paper!</p></div>\n\n## General information\nThe dataset was recorded with Nilspod V2 sensors from Portabiles.\nOne sensor was attached on the instep of each foot and one sensor was attached on the lower back.\nOn loading the transform the coordinate systems of the foot-mounted IMUs to the gaitmap coordinate system.\n\n.. figure:: /images/coordinate_systems/coordinate_transform_nilspodV2_instep_stair_ambulation_ba_liv.svg\n    :alt: coordinate system definition\n    :figclass: align-center\n\nWe provide two `tpcp.Dataset` classes to access the data:\n\n1. :class:`~gaitmap_datasets.StairAmbulationHealthy2021PerTest`: This class allows to access\n   all data and events for each of the performed gait tests individually.\n2. :class:`~gaitmap_datasets.StairAmbulationHealthy2021Full`: This class allows to access the\n   entire recordings for each participant (two recordings per participant) independently of the performed gait tests.\n\nIn the following we will show the usage of both classes and the data that is contained within.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>For this example to work, you need to have a global config set containing the path to the dataset.\n             Check the `README.md` for more information.</p></div>\n\n# StairAmbulationHealthy2021PerTest\nFirst we can simply create an instance of the dataset class and directly see the contained data points.\nNote, that we will enable the loading of all available data (pressure, baro, and hip sensor).\nYou might want to disable that, to reduce the RAM usage and speed up the data loading.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from joblib import Memory\n\nfrom gaitmap_datasets import StairAmbulationHealthy2021PerTest\n\ndataset = StairAmbulationHealthy2021PerTest(\n    include_pressure_data=True,\n    include_baro_data=True,\n    include_hip_sensor=True,\n    memory=Memory(\"../.cache\"),\n)\ndataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that we have 20 participants and each of them has performed 26 gaittests on different level walking and\nstair configurations.\nFor more information about the individual tests see the documentation of the dataset itself.\n\nUsing the dataset class, we can select any subset of tests and participants.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subset = dataset.get_subset(\n    test=[\"stair_long_down_normal\", \"stair_long_up_normal\"], participant=[\"subject_01\", \"subject_02\"]\n)\nsubset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once we have the selection of data we want to work with, we can iterate the dataset object to access the data of\nindividual datapoints or just index it as below.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datapoint = subset[0]\ndatapoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On this datapoint, we can now access the data.\nWe will start with the metadata.\nIt contains all the general information about the participant and the sensors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datapoint.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access the imu data, the pressure data and the barometer data.\nAll of them have an index that marks the seconds from the start of the individual test we selected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data = datapoint.data\nimu_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pressure_data = datapoint.pressure_data\npressure_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "baro_data = datapoint.baro_data\nbaro_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition we provide ground truth information for the event detection.\nAll event data is provided in samples from the start of the test.\n\nNote that we use a trailing `_` to indicate that this is data calculated based on the ground truth and not just the\nIMU data.\n\nFirst, manually labeled stride borders.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "segmented_stride_list = datapoint.segmented_stride_list_\nsegmented_stride_list[\"left_sensor\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second, the events extracted using the pressure-insole.\nNote, that the `min_vel` event is actually calculated based on the IMU data.\nFor more information see the docstring of this property.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "insole_events = datapoint.pressure_insole_event_list_\ninsole_events[\"left_sensor\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As further groundtruth we provide a label for each segmented stride that contains information about the height\nchange during the stride.\nThis information is derived by measuring the heights of the individual stair steps and labeling each stride based\non video, to mark all strides that were performed on a specicic stair configuration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datapoint.get_segmented_stride_list_with_type()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same method used to access this information can also be used to filter the stride list (i.e. only level strides).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datapoint.get_segmented_stride_list_with_type(stride_type=[\"level\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we plot all the relevant data for a single gait test to make it easier to understand.\n\nFor the selected test, we can see that the participant basically started walking right away.\nWhile it can not be easily seen from the raw data IMU itself, the participant walked down a stair in two bouts.\nThis can be more clearly seen in the baro data, which shows a slowly increasing pressure value, indicating a\nreduction in altitude.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfoot = \"right_sensor\"\n_, axs = plt.subplots(nrows=3, figsize=(10, 10), sharex=True)\nimu_data[foot].filter(like=\"gyr\").plot(ax=axs[0])\nimu_data[foot].filter(like=\"acc\").plot(ax=axs[1])\nbaro_data[foot].plot(ax=axs[2])\n\naxs[0].set_ylabel(\"Rate of rotation [deg/s]\")\naxs[1].set_ylabel(\"Acceleration [m/s^2]\")\naxs[2].set_ylabel(\"Air Pressure [mbar]\")\naxs[2].set_xlabel(\"Time [s]\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When zooming in we can see the individual events withing the strides.\nThe min_vel event is in the resting period between strides, and the IC and TC events at the falling and rising\nedges of pressure signal, respectively.\nThe start and endpoints of the segmented strides (dashed lines) are at the maximum of the `gyr_y` signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "foot = \"right_sensor\"\nfig, axs = plt.subplots(nrows=2, figsize=(10, 10), sharex=True)\nimu_data[foot].filter(like=\"gyr\").plot(ax=axs[0])\npressure_data[foot][\"total_force\"].plot(ax=axs[1])\nevents = insole_events[foot].drop(columns=[\"start\", \"end\"])\nevents /= datapoint.sampling_rate_hz\nstyles = [\"ro\", \"gs\", \"b^\", \"m*\"]\nfor style, (i, e) in zip(styles, events.T.iterrows()):\n    e = e.dropna()\n    axs[0].plot(e, imu_data[foot][\"gyr_y\"].loc[e.to_numpy()].to_numpy(), style, label=i, markersize=8)\n    axs[1].plot(e, pressure_data[foot][\"total_force\"].loc[e.to_numpy()].to_numpy(), style, markersize=8)\nfor i, s in segmented_stride_list[foot].iterrows():\n    s /= datapoint.sampling_rate_hz\n    axs[0].axvline(s[\"start\"], color=\"k\", linestyle=\"--\")\n    axs[0].axvline(s[\"end\"], color=\"k\", linestyle=\"--\")\n    axs[1].axvline(s[\"start\"], color=\"k\", linestyle=\"--\")\n    axs[1].axvline(s[\"end\"], color=\"k\", linestyle=\"--\")\n\naxs[0].legend()\naxs[0].set_xlim(12, 15)\naxs[0].set_ylim(-500, 600)\n\naxs[0].set_ylabel(\"Rate of rotation [deg/s]\")\naxs[1].set_ylabel(\"Pressure equivalent weight [kg]\")\naxs[1].set_xlabel(\"Time [s]\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# StairAmbulationHealthy2021Full\nThe StairAmbulationHealthy2021Full dataset is contains the complete recordings of all 20 participants, not cut into\nindividual tests.\nNote, that there are still two recordings per participant.\nThis is because data was collected at two different locations and hence, the data is split into two sections.\n\nThe StairAmbulationHealthy2021Full dataclass can be used equivalently to the StairAmbulationHealthyPerTest dataset.\nThe only difference is that instead of the individual tests, we can see the two parts in the index for the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gaitmap_datasets import StairAmbulationHealthy2021Full\n\ndataset = StairAmbulationHealthy2021Full(\n    include_pressure_data=True,\n    include_baro_data=True,\n    include_hip_sensor=True,\n    memory=Memory(\"../.cache\"),\n)\ndataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subset = dataset.get_subset(participant=\"subject_01\", part=\"part_2\")\nsubset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As most parameters and attributes are identical, we will not repeat them.\n\nOne interesting addition is the `test_list` attribute.\nIf it is required to understand which tests where performed in the respective sessions, we can access them as a\nregion-of-interest list.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subset.test_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When plotting the data in the entire `part_2` recording, we can see that it spans multiple tests including multiple\nwalks up and down various stairs.\n\nIf you would zoom in, you can see that between each test, the participants were instructed to jump up and down 3\ntimes.\nThese jump events were used as marker to cut the individual tests.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imu_data = subset.data\nbaro_data = subset.baro_data\n\nfoot = \"right_sensor\"\n_, axs = plt.subplots(nrows=3, figsize=(10, 10), sharex=True)\nimu_data[foot].filter(like=\"gyr\").plot(ax=axs[0])\nimu_data[foot].filter(like=\"acc\").plot(ax=axs[1])\nbaro_data[foot].plot(ax=axs[2])\nfor i, s in subset.test_list.iterrows():\n    s /= subset.sampling_rate_hz\n    axs[0].axvspan(s[\"start\"], s[\"end\"], color=\"k\", alpha=0.2)\n    axs[1].axvspan(s[\"start\"], s[\"end\"], color=\"k\", alpha=0.2)\n    axs[2].axvspan(s[\"start\"], s[\"end\"], color=\"k\", alpha=0.2)\n\naxs[0].set_ylabel(\"Rate of rotation [deg/s]\")\naxs[1].set_ylabel(\"Acceleration [m/s^2]\")\naxs[2].set_ylabel(\"Air Pressure [mbar]\")\naxs[2].set_xlabel(\"Time [s]\")\n\nplt.xlim(550, 650)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A note on caching\nTo make it possible to interact with the entire dataset, without filling your RAM immediately, all data is only\nloaded once you access the respective data attribute (e.g. `data` or `pressure_data`).\nHowever, this means, if you access the same piece of data multiple times (or multiple pieces of related data),\ndata needs to be loaded again from disk and preprocessed.\nThis is slow.\nTherefore, we allow to use `joblib.Memory` to cache the data in a fast disk cache.\nYou can configure the cache directory using the `memory` parameter of the dataset class.\nKeep in mind, that the cache directory can become quite large.\nWe recommend clearing the cache from time to time, to free up space.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}